{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.stem.porter import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Review_Subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(text, n):\n",
    "    if n == 1:\n",
    "        return text\n",
    "    \n",
    "    text.append(\"<end>\")\n",
    "    ngramList = []\n",
    "    for i in range(len(text) - (n-1)):\n",
    "        ngram = text[i:i+n]\n",
    "        ngramList.append(ngram)\n",
    "    \n",
    "    return ngramList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramDict = {}\n",
    "bigramDict = {}\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def getCountsinRow(row):\n",
    "    text = row[\"text\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    \n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        \n",
    "    unigram = getNgrams(parsedText, 1)\n",
    "    bigram = getNgrams(parsedText, 2)\n",
    "    ngrams = (unigram,bigram)\n",
    "    for index in range(len(ngrams)):\n",
    "        for eachWord in ngrams[index]:\n",
    "            \n",
    "            if index == 0:\n",
    "                #unigram\n",
    "                \n",
    "                if eachWord in unigramDict:\n",
    "                    unigramDict[eachWord] +=1\n",
    "                else:\n",
    "                    unigramDict[eachWord] =1\n",
    "                    \n",
    "            if index == 1:\n",
    "                #bigram\n",
    "                    eachWord = tuple(eachWord)\n",
    "                    if eachWord in bigramDict:\n",
    "                        bigramDict[eachWord] +=1\n",
    "                    else:\n",
    "                        bigramDict[eachWord] =1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the probabilies into unigramsDict and bigramsDict\n",
    "data.apply(getCountsinRow, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unigramDict))\n",
    "print(len(bigramDict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE UNIGRAM/BIGRAM FREQ. INTO A FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "extractList = []\n",
    "for eachKey in unigramDict:\n",
    "    extractList.append([eachKey,unigramDict[eachKey]])\n",
    "\n",
    "pd.DataFrame(extractList, columns = [\"word\", \"count\"]).to_csv(\"unigramProbabilities.csv\", index = False)\n",
    "'''#export unigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export bigrams\n",
    "'''\n",
    "extractList = []\n",
    "for eachKey in bigramDict:\n",
    "    extractList.append([eachKey[0],eachKey[1],bigramDict[eachKey]])\n",
    "    \n",
    "pd.DataFrame(extractList, columns = [\"first\", \"second\", \"count\"]).to_csv(\"bigramProbabilities.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIGRAM VECTOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the vector model in data\n",
    "unigramVM = []\n",
    "def getUnigramReviewVectors(row):\n",
    "    \n",
    "    #we have data,unigrams,bigrams\n",
    "    rowVector = {}\n",
    "    text = row[\"text\"]\n",
    "    score = row[\"score\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        if parsedText[index] in rowVector:\n",
    "            rowVector[parsedText[index]] +=1\n",
    "        else:\n",
    "            rowVector[parsedText[index]] = 1\n",
    "    \n",
    "    if score >= 4:\n",
    "        rowVector[\"<label>\"] = \"good\"\n",
    "    else:\n",
    "        rowVector[\"<label>\"] = \"bad\"\n",
    "        \n",
    "    unigramVM.append(rowVector)\n",
    "    \n",
    "\n",
    "data.apply(getUnigramReviewVectors, axis = 1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE UVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(unigramVM).to_csv(\"UnigramVectorModel.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET TFIDF UNIGRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make inverted index\n",
    "invertedIndex = {}\n",
    "'''\n",
    "invertedIndex\n",
    "the => {index : 1}\n",
    "'''\n",
    "\n",
    "def makeInvertedIndex(row):\n",
    "    #get the bigrams\n",
    "    #for each bigram -> add a count to the inverted index\n",
    "    #do not double count\n",
    "    \n",
    "    #get bigrams\n",
    "    text = row[\"text\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    \n",
    "    for index in range(len(parsedText)):\n",
    "        \n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        eachWord = parsedText[index]\n",
    "    \n",
    "        if eachWord not in invertedIndex:\n",
    "            invertedIndex[eachWord] = [1, {}]\n",
    "\n",
    "        if row.name not in invertedIndex[eachWord]:\n",
    "            invertedIndex[eachWord][0] += 1\n",
    "            invertedIndex[eachWord][1][row.name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(makeInvertedIndex, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDFVM = []\n",
    "def getTFIDFReviewVectors(row):\n",
    "    \n",
    "    #we have data,unigrams,bigrams\n",
    "    rowVector = {}\n",
    "    text = row[\"text\"]\n",
    "    score = row[\"score\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    \n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        \n",
    "        if parsedText[index] in rowVector:\n",
    "            rowVector[parsedText[index]] +=1\n",
    "        else:\n",
    "            rowVector[parsedText[index]] = 1\n",
    "        \n",
    "    #get individual counts\n",
    "    for eachWord in rowVector:\n",
    "        \n",
    "        TF = rowVector[eachWord]/unigramDict[eachWord]\n",
    "        \n",
    "        term = len(invertedIndex[eachWord][1])\n",
    "        \n",
    "        \n",
    "        if term == 0:\n",
    "            term = 1\n",
    "            \n",
    "        IDF = math.log2(2000/term)\n",
    "            \n",
    "        if IDF < 0:\n",
    "            print(eachWord)\n",
    "            \n",
    "        \n",
    "    if score >= 4:\n",
    "        rowVector[\"<label>\"] = \"good\"\n",
    "    else:\n",
    "        rowVector[\"<label>\"] = \"bad\"\n",
    "        \n",
    "    TFIDFVM.append(rowVector)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.apply(getTFIDFReviewVectors, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(TFIDFVM).to_csv(\"UniTFIDFModel.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
