{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Review_Subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(text, n):\n",
    "    if n == 1:\n",
    "        return text\n",
    "    \n",
    "    text.append(\"<end>\")\n",
    "    ngramList = []\n",
    "    for i in range(len(text) - (n-1)):\n",
    "        ngram = text[i:i+n]\n",
    "        ngramList.append(ngram)\n",
    "    \n",
    "    return ngramList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramDict = {}\n",
    "bigramDict = {}\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def getCountsinRow(row):\n",
    "    text = row[\"text\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    \n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        \n",
    "    unigram = getNgrams(parsedText, 1)\n",
    "    bigram = getNgrams(parsedText, 2)\n",
    "    ngrams = (unigram,bigram)\n",
    "    for index in range(len(ngrams)):\n",
    "        for eachWord in ngrams[index]:\n",
    "            \n",
    "            if index == 0:\n",
    "                #unigram\n",
    "                \n",
    "                if eachWord in unigramDict:\n",
    "                    unigramDict[eachWord] +=1\n",
    "                else:\n",
    "                    unigramDict[eachWord] =1\n",
    "                    \n",
    "            if index == 1:\n",
    "                #bigram\n",
    "                    eachWord = tuple(eachWord)\n",
    "                    if eachWord in bigramDict:\n",
    "                        bigramDict[eachWord] +=1\n",
    "                    else:\n",
    "                        bigramDict[eachWord] =1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "1970    None\n",
       "1971    None\n",
       "1972    None\n",
       "1973    None\n",
       "1974    None\n",
       "1975    None\n",
       "1976    None\n",
       "1977    None\n",
       "1978    None\n",
       "1979    None\n",
       "1980    None\n",
       "1981    None\n",
       "1982    None\n",
       "1983    None\n",
       "1984    None\n",
       "1985    None\n",
       "1986    None\n",
       "1987    None\n",
       "1988    None\n",
       "1989    None\n",
       "1990    None\n",
       "1991    None\n",
       "1992    None\n",
       "1993    None\n",
       "1994    None\n",
       "1995    None\n",
       "1996    None\n",
       "1997    None\n",
       "1998    None\n",
       "1999    None\n",
       "Length: 2000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#get the probabilies into unigramsDict and bigramsDict\n",
    "data.apply(getCountsinRow, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6120\n",
      "60028\n"
     ]
    }
   ],
   "source": [
    "print(len(unigramDict))\n",
    "print(len(bigramDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export unigrams\n",
    "extractList = []\n",
    "for eachKey in unigramDict:\n",
    "    extractList.append([eachKey,unigramDict[eachKey]])\n",
    "\n",
    "pd.DataFrame(extractList, columns = [\"word\", \"count\"]).to_csv(\"unigramProbabilities.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export bigrams\n",
    "extractList = []\n",
    "for eachKey in bigramDict:\n",
    "    extractList.append([eachKey[0],eachKey[1],bigramDict[eachKey]])\n",
    "    \n",
    "pd.DataFrame(extractList, columns = [\"first\", \"second\", \"count\"]).to_csv(\"bigramProbabilities.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                               text\n",
      "0         5  I have bought several of the Vitality canned d...\n",
      "1         1  Product arrived labeled as Jumbo Salted Peanut...\n",
      "2         4  This is a confection that has been around a fe...\n",
      "3         2  If you are looking for the secret ingredient i...\n",
      "4         5  Great taffy at a great price.  There was a wid...\n",
      "5         4  I got a wild hair for taffy and ordered this f...\n",
      "6         5  This saltwater taffy had great flavors and was...\n",
      "7         5  This taffy is so good.  It is very soft and ch...\n",
      "8         5  Right now I'm mostly just sprouting this so my...\n",
      "9         5  This is a very healthy dog food. Good for thei...\n",
      "10        5  I don't know if it's the cactus or the tequila...\n",
      "11        5  One of my boys needed to lose some weight and ...\n",
      "12        1  My cats have been happily eating Felidae Plati...\n",
      "13        4  good flavor! these came securely packed... the...\n",
      "14        5  The Strawberry Twizzlers are my guilty pleasur...\n",
      "15        5  My daughter loves twizzlers and this shipment ...\n",
      "16        2  I love eating them and they are good for watch...\n",
      "17        5  I am very satisfied with my Twizzler purchase....\n",
      "18        5  Twizzlers, Strawberry my childhood favorite ca...\n",
      "19        5  Candy was delivered very fast and was purchase...\n",
      "20        5  My husband is a Twizzlers addict.  We've bough...\n",
      "21        5  I bought these for my husband who is currently...\n",
      "22        5  I can remember buying this candy as a kid and ...\n",
      "23        5  I love this candy.  After weight watchers I ha...\n",
      "24        5  I have lived out of the US for over 7 yrs now,...\n",
      "25        5  Product received is as advertised.<br /><br />...\n",
      "26        1  The candy is just red , No flavor . Just  plan...\n",
      "27        4  I was so glad Amazon carried these batteries. ...\n",
      "28        5  I got this for my Mum who is not diabetic but ...\n",
      "29        5  I don't know if it's the cactus or the tequila...\n",
      "...     ...                                                ...\n",
      "1970      4  I have had waffles from other mixes that are t...\n",
      "1971      4  This lands in the gormet category for sure.  H...\n",
      "1972      4  I'm not normally a big fan of mixes but this i...\n",
      "1973      4  The pancakes were delicious, but they weren't ...\n",
      "1974      4  On a whim, I picked up a two-pack of Stonewall...\n",
      "1975      4  No matter how you mess up the recipe, this Mix...\n",
      "1976      1  I have an immense love for pancakes.  I have b...\n",
      "1977      4  Heavily touted by the reviews, decided to try....\n",
      "1978      1  This expensive pancake mix tastes so processed...\n",
      "1979      1  Part of me wants to ask for a refund. I bought...\n",
      "1980      1  This is NOT A SUMMER SAMPLER<br /><br />The ma...\n",
      "1981      1  Thought I was ordering summer tea flavors, got...\n",
      "1982      4  As a new Keurig owner, I'm trying as many \"sam...\n",
      "1983      4  very good price and we love our keurig trying ...\n",
      "1984      4  I haven't had a chance to try these out yet, b...\n",
      "1985      4  There are some types I really like--especially...\n",
      "1986      4  I got this on a special and we are coffee love...\n",
      "1987      4  This is an excellent product for the non-glute...\n",
      "1988      4  Not as good as Sesmark Savory Rice Minis, but ...\n",
      "1989      4  This freeze dried ice cream is great! It taste...\n",
      "1990      4  My 1 year old son does really like these- andt...\n",
      "1991      4  My dog thinks he was born into the gentry and ...\n",
      "1992      4  Watch out for the fat-- 9g of fat per 17g serv...\n",
      "1993      4  This tea is very good.  I discovered it while ...\n",
      "1994      4  I love this TEA. It has a very smooth taste an...\n",
      "1995      4  I found this exact same stuff at the dollar st...\n",
      "1996      4  I got tired of overpaying for tea at Teavana s...\n",
      "1997      4  Using the entire sauce packet is over kill, le...\n",
      "1998      4  This is pretty good stuff. You can't expect a ...\n",
      "1999      4  \"It tastes better than it looks\" was the first...\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "1970    None\n",
       "1971    None\n",
       "1972    None\n",
       "1973    None\n",
       "1974    None\n",
       "1975    None\n",
       "1976    None\n",
       "1977    None\n",
       "1978    None\n",
       "1979    None\n",
       "1980    None\n",
       "1981    None\n",
       "1982    None\n",
       "1983    None\n",
       "1984    None\n",
       "1985    None\n",
       "1986    None\n",
       "1987    None\n",
       "1988    None\n",
       "1989    None\n",
       "1990    None\n",
       "1991    None\n",
       "1992    None\n",
       "1993    None\n",
       "1994    None\n",
       "1995    None\n",
       "1996    None\n",
       "1997    None\n",
       "1998    None\n",
       "1999    None\n",
       "Length: 2000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the vector model in data\n",
    "unigramVM = []\n",
    "def getUnigramReviewVectors(row):\n",
    "    \n",
    "    #we have data,unigrams,bigrams\n",
    "    rowVector = {}\n",
    "    text = row[\"text\"]\n",
    "    score = row[\"score\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        score = unigramDict[parsedText[index]]\n",
    "        rowVector[parsedText[index]] = score\n",
    "    \n",
    "    if score > 4:\n",
    "        rowVector[\"<label>\"] = \"good\"\n",
    "    else:\n",
    "        rowVector[\"<label>\"] = \"bad\"\n",
    "        \n",
    "    unigramVM.append(rowVector)\n",
    "    \n",
    "\n",
    "data.apply(getUnigramReviewVectors, axis = 1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(unigramVM).to_csv(\"UnigramVectorModel.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unigramVM)\n",
    "len(unigramDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
