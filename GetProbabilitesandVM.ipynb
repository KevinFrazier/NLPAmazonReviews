{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Review_Subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(text, n):\n",
    "    if n == 1:\n",
    "        return text\n",
    "    \n",
    "    text.append(\"<end>\")\n",
    "    ngramList = []\n",
    "    for i in range(len(text) - (n-1)):\n",
    "        ngram = text[i:i+n]\n",
    "        ngramList.append(ngram)\n",
    "    \n",
    "    return ngramList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramDict = {}\n",
    "bigramDict = {}\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def getCountsinRow(row):\n",
    "    text = row[\"text\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    \n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        \n",
    "    unigram = getNgrams(parsedText, 1)\n",
    "    bigram = getNgrams(parsedText, 2)\n",
    "    ngrams = (unigram,bigram)\n",
    "    for index in range(len(ngrams)):\n",
    "        for eachWord in ngrams[index]:\n",
    "            \n",
    "            if index == 0:\n",
    "                #unigram\n",
    "                \n",
    "                if eachWord in unigramDict:\n",
    "                    unigramDict[eachWord] +=1\n",
    "                else:\n",
    "                    unigramDict[eachWord] =1\n",
    "                    \n",
    "            if index == 1:\n",
    "                #bigram\n",
    "                    eachWord = tuple(eachWord)\n",
    "                    if eachWord in bigramDict:\n",
    "                        bigramDict[eachWord] +=1\n",
    "                    else:\n",
    "                        bigramDict[eachWord] =1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the probabilies into unigramsDict and bigramsDict\n",
    "data.apply(getCountsinRow, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unigramDict))\n",
    "print(len(bigramDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export unigrams\n",
    "extractList = []\n",
    "for eachKey in unigramDict:\n",
    "    extractList.append([eachKey,unigramDict[eachKey]])\n",
    "\n",
    "pd.DataFrame(extractList, columns = [\"word\", \"count\"]).to_csv(\"unigramProbabilities.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export bigrams\n",
    "extractList = []\n",
    "for eachKey in bigramDict:\n",
    "    extractList.append([eachKey[0],eachKey[1],bigramDict[eachKey]])\n",
    "    \n",
    "pd.DataFrame(extractList, columns = [\"first\", \"second\", \"count\"]).to_csv(\"bigramProbabilities.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the vector model in data\n",
    "unigramVM = []\n",
    "def getUnigramReviewVectors(row):\n",
    "    \n",
    "    #we have data,unigrams,bigrams\n",
    "    rowVector = {}\n",
    "    text = row[\"text\"]\n",
    "    score = row[\"score\"]\n",
    "    parsedText = re.findall(\"(\\w+)\", text)\n",
    "    for index in range(len(parsedText)):\n",
    "        parsedText[index] = stemmer.stem(parsedText[index])\n",
    "        parsedText[index] = parsedText[index].lower()\n",
    "        #score = unigramDict[parsedText[index]]\n",
    "        if parsedText[index] in rowVector:\n",
    "            rowVector[parsedText] +=1\n",
    "        else:\n",
    "            rowVector[parsedText] = 1\n",
    "    \n",
    "    if score > 4:\n",
    "        rowVector[\"<label>\"] = \"good\"\n",
    "    else:\n",
    "        rowVector[\"<label>\"] = \"bad\"\n",
    "        \n",
    "    unigramVM.append(rowVector)\n",
    "    \n",
    "\n",
    "data.apply(getUnigramReviewVectors, axis = 1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(unigramVM).to_csv(\"UnigramVectorModel.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unigramVM)\n",
    "len(unigramDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
